import json
from transformers import GPT2LMHeadModel, GPT2Tokenizer
from collections import deque

# GPT-2 ëª¨ë¸ ë¡œë“œ
model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPT2LMHeadModel.from_pretrained(model_name)

# Bangbooì˜ ê¸°ì–µ ì‹œìŠ¤í…œ
MEMORY_FILE = "bangboo_memory.json"
CONVERSATION_HISTORY_FILE = "conversation_history.json"  # ëŒ€í™” ê¸°ë¡ íŒŒì¼
short_term_memory = deque(maxlen=10)  # ë‹¨ê¸° ê¸°ì–µ (ìµœëŒ€ 10ê°œì˜ ìµœê·¼ ëŒ€í™”)

# ê¸°ì–µ ì´ˆê¸°í™” ë° ê´€ë¦¬
def load_memory():
    try:
        with open(MEMORY_FILE, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def save_memory(memory):
    with open(MEMORY_FILE, "w") as f:
        json.dump(memory, f, indent=4)

memory = load_memory()

# ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
def load_conversation_history():
    try:
        with open(CONVERSATION_HISTORY_FILE, "r") as f:
            history = json.load(f)
            return deque(history, maxlen=10)
    except FileNotFoundError:
        return deque(maxlen=10)

def save_conversation_history(history):
    with open(CONVERSATION_HISTORY_FILE, "w") as f:
        json.dump(list(history), f, indent=4)

short_term_memory = load_conversation_history()  # ì´ì „ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°

# ê¸°ì–µ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def save_user_memory(user_id, key, value):
    if user_id not in memory:
        memory[user_id] = {}
    memory[user_id][key] = value
    save_memory(memory)

def get_user_memory(user_id, key):
    return memory.get(user_id, {}).get(key)

# ì›…ë‚˜ ìƒì„± í•¨ìˆ˜
def generate_woongna_response(user_input):
    # ëŒ€ë‹µì˜ ê¸¸ì´ì— ë”°ë¼ "ì›…ë‚˜"ì˜ ê¸¸ì´ë¥¼ ì¡°ì •
    response_length = len(user_input)
    woongna = "ì›…" + "ë‚˜" * (response_length // 5 + 1)
    
    # "ë‚˜"ê°€ 3ê°œ ì´ìƒì¼ ê²½ìš° ì ì ˆíˆ "ì›…ë‚˜"ë¡œ ë°”ê¾¸ê¸°
    if len(woongna) > 6:  # "ì›…ë‚˜ë‚˜ë‚˜"ì²˜ëŸ¼ 3ê°œ ì´ìƒì¸ ê²½ìš°
        woongna_list = ["ì›…ë‚˜" for _ in range((len(woongna) - 1) // 2)]
        woongna = " ".join(woongna_list)

    # ëŒ€ë‹µ ë‚´ìš©ì— ë”°ë¼ ê¸°í˜¸ ì¶”ê°€
    if "?" in user_input:
        symbol = "?!"
    elif "!" in user_input:
        symbol = "!!"
    elif "ì‹«ì–´" in user_input or "ì•„ë‹ˆ" in user_input:
        symbol = "..."
    else:
        symbol = "."
    
    # ìµœì¢… ì›…ë‚˜ ëŒ€ë‹µ ìƒì„±
    final_response = f"{woongna} ({user_input}){symbol}"
    return final_response

# GPT-2ë¥¼ ì‚¬ìš©í•œ Bangboo ëŒ€í™” ìƒì„±
def generate_bangboo_reply(context):
    input_ids = tokenizer.encode(context, return_tensors="pt")
    output = model.generate(
        input_ids,
        max_length=150,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        top_k=50,
        top_p=0.9,
        temperature=0.7
    )
    reply = tokenizer.decode(output[0], skip_special_tokens=True)
    return reply

# Bangbooì˜ ëŒ€í™” ë¡œì§
def bangboo_reply(user_id, user_input):
    # ë‹¨ê¸° ê¸°ì–µì— ëŒ€í™” ì €ì¥
    short_term_memory.append(f"User: {user_input}")

    # ì‚¬ìš©ì ì´ë¦„ ê¸°ì–µ
    user_name = get_user_memory(user_id, "name")
    if user_name is None and "ì´ë¦„" in user_input:
        user_name = user_input.split("ì´ë¦„ì€ ")[-1].strip()
        save_user_memory(user_id, "name", user_name)
        return f"ë°˜ê°€ì›Œìš”, {user_name}! ì´ì œ ì´ë¦„ì„ ê¸°ì–µí• ê²Œìš”!"
    
    # GPT-2 ê¸°ë°˜ ëŒ€í™” ìƒì„±
    context = "\n".join(short_term_memory) + f"\nBangboo: "
    raw_reply = generate_bangboo_reply(context)

    # Bangboo ìŠ¤íƒ€ì¼ ì ìš©
    bangboo_response = f"{raw_reply} ğŸ¾ (Bangboo ìŠ¤íƒ€ì¼!)"

    # ì›…ë‚˜ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜
    woongna_response = generate_woongna_response(user_input)

    # ë‹¨ê¸° ê¸°ì–µ ì¶”ê°€
    short_term_memory.append(f"Bangboo: {bangboo_response}")

    # ìµœì¢… ì¶œë ¥
    return woongna_response

# ëŒ€í™” ì‹¤í–‰
def start_bangboo_conversation():
    user_id = "user123"  # ê³ ì • ì‚¬ìš©ì ID
    print("Bangboo: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Bangbooì—ìš”. ë‹¹ì‹ ê³¼ ëŒ€í™”í•˜ê³  ì‹¶ì–´ìš”!")
    
    while True:
        user_input = input("You: ")
        if user_input.lower() in ["ë", "ì¢…ë£Œ", "bye"]:
            print("Bangboo: ëŒ€í™”í•´ì¤˜ì„œ ê³ ë§ˆì›Œìš”! ë‚˜ì¤‘ì— ë˜ ë§Œë‚˜ìš”! ğŸ¾")
            save_conversation_history(short_term_memory)  # ì¢…ë£Œ ì‹œ ëŒ€í™” ê¸°ë¡ ì €ì¥
            break
        reply = bangboo_reply(user_id, user_input)
        print(f"Bangboo: {reply}")

# ëŒ€í™” ì‹œì‘
start_bangboo_conversation()