import json
import cv2
import torch
import numpy as np
import face_recognition
from transformers import GPT2LMHeadModel, GPT2Tokenizer
from collections import deque
import os
import threading

model_name = "gpt2"  # ë˜ëŠ” "gpt2-medium", "gpt2-large", "gpt2-xl" ë“± ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# YOLOv5 ëª¨ë¸ ë¡œë“œ (Pre-trained)
device = "cuda" if torch.cuda.is_available() else "cpu"
model_yolo = torch.hub.load("ultralytics/yolov5", "yolov5s", pretrained=True).to(device)

# ê¸°ì–µ ì‹œìŠ¤í…œ íŒŒì¼ ë° ë³€ìˆ˜ë“¤
MEMORY_FILE = "bangboo_memory.json"
CONVERSATION_HISTORY_FILE = "conversation_history.json"
short_term_memory = deque(maxlen=200)

# ì–¼êµ´ ë°ì´í„° ì €ì¥ ë³€ìˆ˜
known_face_encodings = []
known_face_names = []

# ì–¼êµ´ ë° ê°ì²´ íƒì§€ í•¨ìˆ˜
def detect_faces_and_objects(frame):
    # ì–¼êµ´ ì¸ì‹
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_locations = face_recognition.face_locations(rgb_frame)
    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)

    # ê°ì²´ íƒì§€
    results = model_yolo(frame)
    detected_objects = results.pandas().xyxy[0]["name"].tolist()

    return face_locations, face_encodings, detected_objects

# ì–¼êµ´ ë“±ë¡ í•¨ìˆ˜
def register_face(frame, name):
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_locations = face_recognition.face_locations(rgb_frame)
    if not face_locations:
        return "Bangboo: ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

    face_encoding = face_recognition.face_encodings(rgb_frame, face_locations)[0]
    known_face_encodings.append(face_encoding)
    known_face_names.append(name)
    return f"Bangboo: {name}ë‹˜ì˜ ì–¼êµ´ì„ ê¸°ì–µí–ˆì–´ìš”!"

# Bangbooì˜ ëŒ€ë‹µ ìƒì„± í•¨ìˆ˜
def generate_bangboo_reply(context):
    input_ids = tokenizer.encode(context, return_tensors="pt")
    output = model.generate(
        input_ids,
        max_length=512,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        top_k=50,
        top_p=0.9,
        temperature=0.8
    )
    reply = tokenizer.decode(output[0], skip_special_tokens=True).strip()
    return reply

# Bangbooì˜ ì›…ë‚˜ ëŒ€ë‹µ ìƒì„± í•¨ìˆ˜
def generate_woongna_response(user_input):
    # GPT-2 ëŒ€ë‹µ ìƒì„±
    context = "\n".join(short_term_memory) + f"\nUser: {user_input}\nBangboo:"
    gpt2_reply = generate_bangboo_reply(context)
    
    # ëŒ€ë‹µ ë ê¸°í˜¸ ì„¤ì •
    if "?" in gpt2_reply:
        symbol = "?!"
    elif "!" in gpt2_reply:
        symbol = "!!"
    else:
        symbol = "."

    # ì›…ë‚˜ ë°˜ë³µ ì²˜ë¦¬
    response_length = len(user_input)
    woongna = "ì›…" + "ë‚˜" * (response_length // 3 + 2)

    # "ë‚˜"ê°€ 3ê°œ ì´ìƒì´ë©´ ë‹¤ì‹œ "ì›…ë‚˜"ë¡œ ë³€í™˜
    if woongna.count("ë‚˜") > 3:
        woongna_list = ["ì›…ë‚˜" for _ in range((response_length // 6) + 1)]
        woongna = " ".join(woongna_list)

    # ìµœì¢… ëŒ€ë‹µ ìƒì„±
    final_response = f"{woongna}{symbol} ({gpt2_reply})"
    return final_response

# ê¸°ì–µ ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def save_memory(memory):
    with open(MEMORY_FILE, "w") as f:
        json.dump(memory, f, indent=4)

def load_memory():
    try:
        with open(MEMORY_FILE, "r") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def save_conversation_history(history):
    with open(CONVERSATION_HISTORY_FILE, "w") as f:
        json.dump(list(history), f, indent=4)

def load_conversation_history():
    try:
        with open(CONVERSATION_HISTORY_FILE, "r") as f:
            history = json.load(f)
            return deque(history, maxlen=200)
    except FileNotFoundError:
        return deque(maxlen=200)

memory = load_memory()
short_term_memory = load_conversation_history()

# ê¸°ì–µ ê´€ë ¨ í•¨ìˆ˜
def save_user_memory(user_id, key, value):
    if user_id not in memory:
        memory[user_id] = {}
    memory[user_id][key] = value
    save_memory(memory)

def get_user_memory(user_id, key):
    return memory.get(user_id, {}).get(key)

# Bangbooì˜ ëŒ€í™” ë¡œì§
def bangboo_reply(user_id, user_input, frame=None):
    # ì–¼êµ´ ë“±ë¡ ìš”ì²­ ì²˜ë¦¬
    if "ì–¼êµ´ ë“±ë¡" in user_input:
        name = user_input.split("ì´ë¦„ì€ ")[-1].strip()
        if frame is not None:
            return register_face(frame, name)

    # íƒì§€ ê²°ê³¼ ì¶œë ¥ ìš”ì²­
    if "ì•ì— ë­ê°€ ë³´ì´ëƒ" in user_input or "ì£¼ë³€ì— ë­ê°€ ìˆì–´" in user_input:
        return "Bangboo: ì§€ê¸ˆ ì£¼ë³€ì„ íƒì§€í•˜ê³  ìˆì–´ìš”!"

    # ì‚¬ìš©ì ì´ë¦„ ê¸°ì–µ
    user_name = get_user_memory(user_id, "name")
    if user_name is None and "ì´ë¦„" in user_input:
        user_name = user_input.split("ì´ë¦„ì€ ")[-1].strip()
        save_user_memory(user_id, "name", user_name)
        return f"ë°˜ê°€ì›Œìš”, {user_name}! ì´ì œ ì´ë¦„ì„ ê¸°ì–µí• ê²Œìš”!"

    # ì›…ë‚˜ ìŠ¤íƒ€ì¼ì˜ GPT-2 ëŒ€ë‹µ ìƒì„±
    woongna_response = generate_woongna_response(user_input)
    short_term_memory.append(f"User: {user_input}")
    short_term_memory.append(f"Bangboo: {woongna_response}")
    return woongna_response

# ì¹´ë©”ë¼ ì‹¤í–‰ ë° íƒì§€ ë°˜ë³µ
def capture_camera():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("Bangboo: ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€í™” ê¸°ëŠ¥ë§Œ í™œì„±í™”ë©ë‹ˆë‹¤.")
        return

    while True:
        ret, frame = cap.read()
        if not ret:
            print("Bangboo: ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break
        
        cv2.imshow('Camera', frame)

        # ì–¼êµ´ ë° ê°ì²´ íƒì§€
        face_locations, face_encodings, detected_objects = detect_faces_and_objects(frame)

        # ì–¼êµ´ ì¸ì‹
        recognized_names = []
        for face_encoding in face_encodings:
            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)
            name = "Unknown"

            if True in matches:
                match_index = matches.index(True)
                name = known_face_names[match_index]

            recognized_names.append(name)

        # ì–¼êµ´ì— ì‚¬ê°í˜• ë° ì´ë¦„ í‘œì‹œ
        for (top, right, bottom, left), name in zip(face_locations, recognized_names):
            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
            cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

        # í™”ë©´ì— í”„ë ˆì„ ì¶œë ¥
        cv2.imshow("Bangboo Camera", frame)

        if cv2.waitKey(1) & 0xFF == ord("q"):
            break

    cap.release()
    cv2.destroyAllWindows()

# í”„ë¡œê·¸ë¨ ì‹¤í–‰
def start_bangboo_conversation():
    user_id = "user123"
    print("Bangboo: ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Bangbooì—ìš”. ë‹¹ì‹ ê³¼ ëŒ€í™”í•˜ê³  ì‹¶ì–´ìš”!")

    cap = cv2.VideoCapture(0)
    while True:
        user_input = input("You: ")
        if user_input.lower() in ["ë", "ì¢…ë£Œ", "bye"]:
            print("Bangboo: ëŒ€í™”í•´ì¤˜ì„œ ê³ ë§ˆì›Œìš”! ë‚˜ì¤‘ì— ë˜ ë§Œë‚˜ìš”! ğŸ¾")
            save_conversation_history(short_term_memory)
            break

        ret, frame = cap.read()  # ì¹´ë©”ë¼ í”„ë ˆì„ ì½ê¸°
        if not ret:
            frame = None

        reply = bangboo_reply(user_id, user_input, frame)
        print(reply)

    cap.release()

# ì¹´ë©”ë¼ ì‹¤í–‰ê³¼ ëŒ€í™”ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰
camera_thread = threading.Thread(target=capture_camera)
camera_thread.start()

start_bangboo_conversation()
